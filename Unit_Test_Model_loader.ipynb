{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNR1j+B1DLImna5HH/uXFi5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "245632d49aff4e85a6069ee1d0a1c8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e852d4eb2b8c40548451282b88c01b53",
              "IPY_MODEL_8314b80c384449f2b24a3641b1e500eb",
              "IPY_MODEL_81605237fe054a929d75d97b195954d5"
            ],
            "layout": "IPY_MODEL_f0714765681643fe84d9c85cb5cdf175"
          }
        },
        "e852d4eb2b8c40548451282b88c01b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0086c3e5427e4149a46b062b9c361403",
            "placeholder": "​",
            "style": "IPY_MODEL_258a060e0bff453c8870f8392ed0455c",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "8314b80c384449f2b24a3641b1e500eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eea54922a3e04bf681978bb5569b61f3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_789b92ba67db451dbdc0ff2e04df27fd",
            "value": 2
          }
        },
        "81605237fe054a929d75d97b195954d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8acc72fd3eba4f098fcf713adc9d8f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_0f17ca0ae9cc4a959037cc8c0e937e9e",
            "value": " 2/2 [00:04&lt;00:00,  2.05s/it]"
          }
        },
        "f0714765681643fe84d9c85cb5cdf175": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0086c3e5427e4149a46b062b9c361403": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "258a060e0bff453c8870f8392ed0455c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eea54922a3e04bf681978bb5569b61f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "789b92ba67db451dbdc0ff2e04df27fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8acc72fd3eba4f098fcf713adc9d8f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f17ca0ae9cc4a959037cc8c0e937e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WilliamCollins-a/LLMHallucinations/blob/Semantic-Entropy/Unit_Test_Model_loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST TO LOAD THE MODEL"
      ],
      "metadata": {
        "id": "7NjJ27dXU67d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8JfUytdvA3j",
        "outputId": "02d8180b-b420-4bfb-d9ec-984f4e1e3469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Import the 'drive' module from Google Colab to enable access to Google Drive files and\n",
        "from google.colab import drive\n",
        "# Mount Google Drive to the Colab environment\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir('/content/drive/MyDrive/Colab Notebooks/'))\n"
      ],
      "metadata": {
        "id": "F1qHLkrtT7jy",
        "outputId": "3b6c78f3-1d3c-41bb-da53-6ef72587c1a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Copy of Welcome to Colaboratory', 'Untitled0.ipynb', 'Untitled1.ipynb', 'Copy of Untitled2.ipynb', 'loadqa.ipynb', 'Copy of loadqa.ipynb', 'Untitled2.ipynb', 'Copy of json_data_loader (1).ipynb', 'llama.ipynb', 'Copy of model_loader.ipynb', 'Copy of json_data_loader.ipynb', 'test.ipynb', 'model_loader.txt', 'json_data_loader.txt', 'model_loader.py.txt', 'json_data_loader.py.txt', 'model_loader_output.txt', 'json_data_loader_output.txt', 'experiment_details.pkl', 'generated_answers.json', 'model_loader.ipynb', 'test.json', 'vb3.ipynb', 'test_data.json', 'test_res.json', 'semantic_entropies.json', 'json_data_loader.ipynb', 'Untitled', 'output.ipynb', 'general_data.json', 'summarization_data.json', 'qa_data.json', 'Util.py', '__pycache__', 'Baseline.ipynb', 'chainpoll (1).ipynb', 'chainpoll.ipynb', 'updated_responses2.json', 'generated_responses3.json', 'semantics_entropy_results.json', 'updated_responses3.json', 'semantic_entropies_responses3.json', 'generate_responses.ipynb', 'hallucination_results.json', 'non-fabrication_check.json', 'generated_responses_with_labels.json', 'semantic_entropies_responses1.json', 'processed_responses.json', 'semantic_entropies_responses4.json', 'processed_responses1.json', 'updated_responses1.json', 'updated_responses.json', 'Ver2.0_Knowhalu.ipynb', 'processed_responses2.json', 'Untitled3.ipynb', 'Semantic_entropy_results.json', 'processed_responses4.json', 'updated_responses_with_semantics.json', 'prediction_results.json', 'updated_generated_responses.json', 'Untitled4.ipynb', 'Copy of Untitled5.ipynb', 'Copy of COT.ipynb', 'COT.ipynb', 'generated_responses2.json', 'generated_responses1.json', 'generated_responses.json', 'semantic_entropy.json', 'semantic_entropy1.json', 'semantic_entropy2.json', 'semantic_entropy3.json', 'semantic_entropy4.json', 'semantic_entropy5.json', 'SemanticEntropyqa.ipynb', 'Unit_Test_Model_loader.ipynb']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Use the %run magic command to run the model_loader notebook\n",
        "%run \"/content/drive/MyDrive/Colab Notebooks/model_loader.ipynb\"\n",
        "\n",
        "import unittest\n",
        "from unittest.mock import patch, MagicMock\n",
        "import torch\n",
        "\n",
        "class TestLoadModel(unittest.TestCase):\n",
        "\n",
        "    @patch(\"transformers.AutoTokenizer.from_pretrained\")\n",
        "    @patch(\"transformers.AutoModelForCausalLM.from_pretrained\")\n",
        "    @patch(\"torch.cuda.is_available\", return_value=True)  # Mocking GPU availability check\n",
        "    def test_load_model(self, mock_is_available, mock_model_pretrained, mock_tokenizer_pretrained):\n",
        "        # Mock the returned objects from from_pretrained methods\n",
        "        mock_tokenizer = MagicMock()\n",
        "        mock_model = MagicMock()\n",
        "\n",
        "        mock_tokenizer_pretrained.return_value = mock_tokenizer\n",
        "        mock_model_pretrained.return_value = mock_model\n",
        "\n",
        "        # Call the load_model function from the notebook\n",
        "        model, tokenizer = load_model()\n",
        "\n",
        "        # Assertions to check if the model and tokenizer are correctly returned\n",
        "        self.assertIs(model, mock_model)\n",
        "        self.assertIs(tokenizer, mock_tokenizer)\n",
        "\n",
        "        # Check if GPU was detected as available\n",
        "        mock_is_available.assert_called_once()\n",
        "\n",
        "        # Verify that the model and tokenizer were loaded using the correct calls\n",
        "        mock_tokenizer_pretrained.assert_called_once_with(\"meta-llama/Llama-2-7b-chat-hf\", use_fast=True, token=\"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\")\n",
        "        mock_model_pretrained.assert_called_once()\n",
        "\n",
        "    @patch(\"transformers.AutoTokenizer.from_pretrained\")\n",
        "    @patch(\"transformers.AutoModelForCausalLM.from_pretrained\")\n",
        "    @patch(\"torch.cuda.is_available\", return_value=False)  # Simulate no GPU availability\n",
        "    def test_load_model_no_gpu(self, mock_is_available, mock_model_pretrained, mock_tokenizer_pretrained):\n",
        "        # Mock the returned objects from from_pretrained methods\n",
        "        mock_tokenizer = MagicMock()\n",
        "        mock_model = MagicMock()\n",
        "\n",
        "        mock_tokenizer_pretrained.return_value = mock_tokenizer\n",
        "        mock_model_pretrained.return_value = mock_model\n",
        "\n",
        "        # Call the load_model function from the notebook\n",
        "        model, tokenizer = load_model()\n",
        "\n",
        "        # Assertions to check if the model and tokenizer are correctly returned\n",
        "        self.assertIs(model, mock_model)\n",
        "        self.assertIs(tokenizer, mock_tokenizer)\n",
        "\n",
        "        # Check if GPU was not detected\n",
        "        mock_is_available.assert_called_once()\n",
        "\n",
        "# Run the tests\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(argv=[''], exit=False)\n"
      ],
      "metadata": {
        "id": "bIbZlN9TUjVp",
        "outputId": "8857d387-f368-4f41-c352-da17857a7b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969,
          "referenced_widgets": [
            "245632d49aff4e85a6069ee1d0a1c8de",
            "e852d4eb2b8c40548451282b88c01b53",
            "8314b80c384449f2b24a3641b1e500eb",
            "81605237fe054a929d75d97b195954d5",
            "f0714765681643fe84d9c85cb5cdf175",
            "0086c3e5427e4149a46b062b9c361403",
            "258a060e0bff453c8870f8392ed0455c",
            "eea54922a3e04bf681978bb5569b61f3",
            "789b92ba67db451dbdc0ff2e04df27fd",
            "8acc72fd3eba4f098fcf713adc9d8f7b",
            "0f17ca0ae9cc4a959037cc8c0e937e9e"
          ]
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Found existing installation: bitsandbytes 0.44.1\n",
            "Uninstalling bitsandbytes-0.44.1:\n",
            "  Successfully uninstalled bitsandbytes-0.44.1\n",
            "Found existing installation: accelerate 1.0.1\n",
            "Uninstalling accelerate-1.0.1:\n",
            "  Successfully uninstalled accelerate-1.0.1\n",
            "Collecting bitsandbytes\n",
            "  Using cached bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting accelerate\n",
            "  Using cached accelerate-1.0.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Using cached bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "Using cached accelerate-1.0.1-py3-none-any.whl (330 kB)\n",
            "Installing collected packages: bitsandbytes, accelerate\n",
            "Successfully installed accelerate-1.0.1 bitsandbytes-0.44.1\n",
            "Loading the tokenizer...\n",
            "Loading the model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "245632d49aff4e85a6069ee1d0a1c8de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.008s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully.\n",
            "Model is already loaded on the GPU.\n",
            "Loading the tokenizer...\n",
            "Loading the model...\n",
            "Model loaded successfully.\n",
            "Model is already loaded on the GPU.\n",
            "Loading the tokenizer...\n",
            "Loading the model...\n",
            "Model loaded successfully.\n",
            "No GPU detected, running on CPU.\n"
          ]
        }
      ]
    }
  ]
}